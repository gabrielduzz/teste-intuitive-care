# Teste T√©cnico - Intuitive Care

Aplica√ß√£o Full Stack desenvolvida para monitoramento, an√°lise e visualiza√ß√£o de despesas de operadoras de planos de sa√∫de, utilizando dados abertos da ANS.

![Home_Preview](screenshots/home.png)
![Graph_Preview](screenshots/graph.png)
![Company_Preview](screenshots/company.png)
![Expenses_Preview](screenshots/expenses.png)

## üìã Sobre o Projeto

Este projeto consiste em uma solu√ß√£o ponta-a-ponta (End-to-End) que realiza:
1.  **ETL Automatizado:** Scraping, limpeza, transforma√ß√£o e valida√ß√£o de dados da ANS.
2.  **API RESTful:** Backend perform√°tico para servir dados paginados e estat√≠sticas.
3.  **Dashboard Interativo:** Frontend moderno para visualiza√ß√£o de indicadores e hist√≥rico financeiro.

---

## üöÄ Como Executar

O projeto foi desenhado para ser executado de forma simples, mas permite controle granular se necess√°rio.

### Pr√©-requisitos
- **Docker e Docker Compose**
- **Python 3.10+**
- **Node.js 18+**


# Crie e ative o ambiente virtual
```bash
python -m venv venv
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate
```

### Execu√ß√£o Autom√°tica ‚ö°

Criei scripts de automa√ß√£o que configuram o ambiente, sobem o banco, instalam depend√™ncias e rodam o pipeline de dados completo.

**No Windows:**
```bash
./run.bat
```

### üêß No Linux/Mac
```bash
chmod +x run.sh
./run.sh   
```
**O que esse script faz?**
Ele automatiza o setup para voc√™ n√£o perder tempo:

1.  Limpa volumes antigos do Docker, pra garantir que n√£o tenha lixo de execu√ß√µes anteriores.
    
2.  Sobe o container do PostgreSQL.
    
3.  Roda o pipeline completo de ETL (scraping -> processamento -> importa√ß√£o pro banco).
    
4.  Te avisa quando terminar.
    

### üêç Preparando o Backend

Em um terminal separado:

```bash
# Suba o servidor
uvicorn backend.main:app --reload
```

*   **API:** http://localhost:8000
    
*   **Docs (Swagger):** http://localhost:8000/docs
    

### üé® Iniciando o Frontend

Em outro terminal:
```bash
cd frontend
npm install
npm run dev
```

*   **Dashboard:** http://localhost:5173
    

### ‚ö†Ô∏è Nota sobre os Dados (Backup de Seguran√ßa)

O script tenta baixar os dados direto do site da ANS em tempo real. Mas sabemos que sites do governo √†s vezes ficam inst√°veis ou lentos.

**Plano B:** J√° deixei os arquivos .csv processados e prontos na pasta data/processed.Se o script de scraping falhar por conex√£o, o sistema √© inteligente o suficiente para usar esses arquivos locais. Assim voc√™ consegue testar a aplica√ß√£o sem ficar travado esperando download.

‚öñÔ∏è Trade-offs e Decis√µes T√©cnicas
---------------------------------

Durante o desenvolvimento, precisei tomar algumas decis√µes de arquitetura. Abaixo explico o porqu√™ de cada escolha, focando no contexto do teste e boas pr√°ticas.

### 1\. Processamento de Dados (ETL)

**Decis√£o:** Processamento em mem√≥ria com Pandas.

**Por que?** O volume de dados trimestral da ANS, embora pare√ßa grande em linhas, cabe tranquilamente na mem√≥ria RAM de m√°quinas modernas. Usar Pandas permitiu escrever um c√≥digo muito mais limpo e r√°pido de implementar do que criar um processamento incremental ou em stream, que seria "overengineering" para esse cen√°rio.
    

### 2\. Tratamento de Dados Inv√°lidos

**Decis√£o:** Rotulagem em vez de Remo√ß√£o.

**Por que?** Em vez de descartar qualquer linha com erro, optei por tentar optei por criar colunas booleanas como CNPJ_Valido, Nome_Valido e Valor_Valido. Isso garante a auditabilidade completa (sabemos exatamente o que veio da fonte). Permite que o analista de neg√≥cios ou o dashboard final decida se quer excluir ou investigar esses registros.


### 3\. Estrat√©gia de Join

**Decis√£o:** Left Join usando Pandas em mem√≥ria.

**Por que?** Usando a coluna RegistroANS como chave de liga√ß√£o, mantive todos os registros de despesas. Se uma operadora n√£o for encontrada no cadastro, as colunas de metadados (Raz√£o Social, UF) ficam nulas, mas o dado financeiro √© preservado. Dado o volume de dados, milhares de linhas, o processamento em mem√≥ria com Pandas √© a solu√ß√£o mais eficiente e simples, evitando a complexidade desnecess√°ria de outros frameworks para esta etapa.


### 4\. Estrat√©gia de Agrega√ß√£o

**Decis√£o:** Agrupamento por Razao_Social e UF.

**Por que?** A ordena√ß√£o foi feita implicitamente pelas chaves de agrupamento, alfab√©tica por Raz√£o Social.


### 5\. Banco de Dados: Normaliza√ß√£o

**Decis√£o:** Tabelas Normalizadas (dim\_companies e fact\_expenses).

**Por que?** Poderia ter feito uma tabela √∫nica , mas optei por separar. A dimens√£o de empresas evita quera Raz√£o Social e UF sejam repetidas v√°rias vezes na tabela de despesas, economizando espa√ßo e facilitando a atualiza√ß√£o cadastral se a empresa mudar de nome.

    
### 6\. Banco de Dados: Tipos Num√©ricos

**Decis√£o:** DECIMAL/NUMERIC ao inv√©s de FLOAT.

**Por que?** √â importante nunca usar Float para dinheiro por causa de erros de arredondamento de ponto flutuante. Usei DECIMAL para garantir precis√£o exata nos centavos.
    

### 7\. Backend: Framework

**Decis√£o:** FastAPI.

*   **Por que?** √â mais perform√°tico que o Flask, pois √© ass√≠ncrono nativo, e j√° me d√° a documenta√ß√£o Swagger de gra√ßa e valida os dados de entrada/sa√≠da com o Pydantic. Isso poupou muito tempo de valida√ß√£o manual de JSON.
    

### 8\. Estrat√©gia de Pagina√ß√£o

**Decis√£o:** Offset-based.

*   **Por que?** Num dashboard administrativo, o usu√°rio quer saber "quantas p√°ginas tem" e poder pular da p√°gina 1 para a 10. Pagina√ß√£o por cursor √© mais r√°pida para volumes gigantes, mas ruim para navega√ß√£o e tabelas cl√°ssicas. Com os √≠ndices que criei no banco, o Offset funciona muito bem aqui.
    

### 9\. Frontend: Busca

**Decis√£o:** Busca no Servidor.

*   **Por que?** Carregar todas as operadoras no navegador do cliente pesaria demais a p√°gina inicial. Fazendo a busca no servidor usando ILIKE no SQL, transferimos o peso do processamento para o banco, que √© feito pra isso, deixando o front leve e r√°pido.
    

### 10\. Frontend: Estado

**Decis√£o:** Composition API & Refs.

*   **Por que?** N√£o usei Pinia ou Vuex porque n√£o precisava. O estado da aplica√ß√£o √© local (apenas a lista da tela atual ou os detalhes da empresa). Usar uma lib de gerenciamento de estado global s√≥ adicionaria complexidade desnecess√°ria sem ganho real. Mantive o princ√≠pio KISS (_Keep It Simple, Stupid_).
    

üåü Diferenciais
---------------

Al√©m do b√°sico funcional, implementei alguns pontos extras para garantir qualidade:

*   **Arquitetura Limpa:** Separei rotas, models e conex√£o com banco. O Frontend tamb√©m est√° componentizado.
    
*   **Performance:**
    
    *   No Frontend, uso Promise.all para disparar requisi√ß√µes de dados da empresa e despesas em paralelo, carregando a tela de detalhes na metade do tempo.
        
    *   No Banco, criei √≠ndices espec√≠ficos para as colunas com mais busca, como o CNPJ.
        
*   **UX/UI:** O layout √© responsivo, tem feedback visual de "Carregando..." e trata erros de forma amig√°vel, sem estourar c√≥digo na cara do usu√°rio.
    
*   **Resili√™ncia:** O script de ETL tem try/except robusto. Se um arquivo falhar, ele avisa e tenta continuar o resto, em vez de quebrar o processo todo.
    

### üìÇ Estrutura do Projeto

- **`backend/`**: C√≥digo fonte da API constru√≠da com FastAPI, incluindo modelos, esquemas e regras de neg√≥cio.
- **`frontend/`**: Aplica√ß√£o cliente desenvolvida em Vue.js, contendo componentes, views e servi√ßos.
- **`data/`**: Diret√≥rio reservado para os arquivos .csv e .zip, brutos e processados, utilizados pelo ETL.
- **`src/`**: Scripts Python respons√°veis por todo o ciclo de vida dos dados.
- **`docker-compose.yml`**: Arquivo de configura√ß√£o para subir o banco de dados PostgreSQL containerizado.
- **`run.bat / run.sh`**: Scripts de conveni√™ncia para configurar e rodar o projeto inteiro com um √∫nico comando.
  

## üîé Queries Anal√≠ticas (SQL)

As consultas SQL solicitadas na **Etapa 3.4** foram desenvolvidas e salvas separadamente para facilitar a revis√£o.

* **Localiza√ß√£o:** Pasta `sql/`
* **Como testar:** Voc√™ pode abrir os arquivos .sql em qualquer cliente de banco de dados (pgAdmin, DBeaver, Datagrip) conectado ao banco do projeto.

**Conte√∫do dos Arquivos:**
1.  **Top 5 Crescimento:** Operadoras que mais cresceram entre trimestres.
2.  **Despesas por UF:** Distribui√ß√£o geogr√°fica e m√©dia por estado.
3.  **Despesas Acima da M√©dia:** Operadoras que superaram a m√©dia geral.


üì¨ Postman
----------

Deixei um arquivo collection.json na raiz. √â s√≥ importar no Postman que todas as rotas j√° est√£o configuradas para teste.
