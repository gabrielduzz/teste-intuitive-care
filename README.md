# Teste T√©cnico - Intuitive Care

Aplica√ß√£o Full Stack desenvolvida para monitoramento, an√°lise e visualiza√ß√£o de despesas de operadoras de planos de sa√∫de, utilizando dados abertos da ANS.

![Home_Preview](screenshots/home.png)
![Graph_Preview](screenshots/graph.png)
![Company_Preview](screenshots/company.png)
![Expenses_Preview](screenshots/expenses.png)

## üìã Sobre o Projeto

Este projeto consiste em uma solu√ß√£o ponta-a-ponta (End-to-End) que realiza:
1.  **ETL Automatizado:** Scraping, limpeza, transforma√ß√£o e valida√ß√£o de dados da ANS.
2.  **API RESTful:** Backend perform√°tico para servir dados paginados e estat√≠sticas.
3.  **Dashboard Interativo:** Frontend moderno para visualiza√ß√£o de indicadores e hist√≥rico financeiro.

---

## üöÄ Como Executar

O projeto foi desenhado para ser executado de forma simples, mas permite controle granular se necess√°rio.

### Pr√©-requisitos
- **Docker e Docker Compose**
- **Python 3.10+**
- **Node.js 18+**


# Crie e ative o ambiente virtual
```bash
python -m venv venv
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate
```

### Execu√ß√£o Autom√°tica ‚ö°

Criei scripts de automa√ß√£o que configuram o ambiente, sobem o banco, instalam depend√™ncias e rodam o pipeline de dados completo.

**No Windows:**
```bash
./run.bat
```

### üêß No Linux/Mac
```bash
chmod +x run.sh
./run.sh   
```
**O que esse script faz?**
Ele automatiza o setup para voc√™ n√£o perder tempo:

1.  Limpa volumes antigos do Docker (pra garantir que n√£o tenha lixo de execu√ß√µes anteriores).
    
2.  Sobe o container do PostgreSQL.
    
3.  Roda o pipeline completo de ETL (scraping -> processamento -> importa√ß√£o pro banco).
    
4.  Te avisa quando terminar.
    

### üêç Preparando o Backend

Em um terminal separado:

```bash
# Suba o servidor
uvicorn backend.main:app --reload
```

*   **API:** http://localhost:8000
    
*   **Docs (Swagger):** http://localhost:8000/docs
    

### üé® Iniciando o Frontend

Em outro terminal:
```bash
cd frontend
npm install
npm run dev
```

*   **Dashboard:** http://localhost:5173
    

### ‚ö†Ô∏è Nota sobre os Dados (Backup de Seguran√ßa)

O script tenta baixar os dados direto do site da ANS em tempo real. Mas a gente sabe que sites do governo √†s vezes ficam inst√°veis ou lentos.

**Plano B:** J√° deixei os arquivos .csv processados e prontos na pasta data/processed.Se o script de scraping falhar por conex√£o, o sistema √© inteligente o suficiente para usar esses arquivos locais. Assim voc√™ consegue testar a aplica√ß√£o sem ficar travado esperando download.

‚öñÔ∏è Trade-offs e Decis√µes T√©cnicas
---------------------------------

Durante o desenvolvimento, precisei tomar algumas decis√µes de arquitetura. Abaixo explico o porqu√™ de cada escolha, focando no contexto do teste e boas pr√°ticas.

### 1\. Processamento de Dados (ETL)

**Decis√£o:** Processamento em Mem√≥ria (Pandas).

*   **Por que?** O volume de dados trimestral da ANS, embora pare√ßa grande em linhas, cabe tranquilamente na mem√≥ria RAM de m√°quinas modernas. Usar Pandas permitiu escrever um c√≥digo muito mais limpo e r√°pido de implementar do que criar um processamento incremental ou em stream, que seria "overengineering" para esse cen√°rio.
    

### 2\. Tratamento de Dados Inv√°lidos

**Decis√£o:** Limpeza e Padroniza√ß√£o.

*   **Por que?** Em vez de descartar qualquer linha com erro, optei por tentar salvar o dado. Para CNPJs, removi caracteres n√£o num√©ricos e garanti o _padding_ com zeros √† esquerda. Se mesmo assim o dado for inv√°lido, ele √© mantido para fins de auditoria, mas n√£o entra nas m√©tricas financeiras cr√≠ticas.
    

### 3\. Banco de Dados: Normaliza√ß√£o

**Decis√£o:** Tabelas Normalizadas (dim\_companies e fact\_expenses).

*   **Por que?** Poderia ter feito uma tabela √∫nica (plana), mas optei por separar. A dimens√£o de empresas (dim\_companies) evita que a gente repita a Raz√£o Social e UF milh√µes de vezes na tabela de despesas, economizando espa√ßo e facilitando a atualiza√ß√£o cadastral se a empresa mudar de nome.
    

### 4\. Banco de Dados: Tipos Num√©ricos

**Decis√£o:** DECIMAL/NUMERIC ao inv√©s de FLOAT.

*   **Por que?** Regra de ouro em sistemas financeiros: nunca use Float para dinheiro por causa de erros de arredondamento de ponto flutuante. Usei DECIMAL para garantir precis√£o exata nos centavos.
    

### 5\. Backend: Framework

**Decis√£o:** FastAPI.

*   **Por que?** √â mais perform√°tico que o Flask (ass√≠ncrono nativo) e a melhor parte: ele j√° me d√° a documenta√ß√£o Swagger de gra√ßa e valida os dados de entrada/sa√≠da com o Pydantic. Isso poupou muito tempo de valida√ß√£o manual de JSON.
    

### 6\. Estrat√©gia de Pagina√ß√£o

**Decis√£o:** Offset-based (LIMIT/OFFSET).

*   **Por que?** Num dashboard administrativo, o usu√°rio quer saber "quantas p√°ginas tem" e poder pular da p√°gina 1 para a 10. Pagina√ß√£o por cursor (como em redes sociais) √© mais r√°pida para volumes gigantes, mas ruim para navega√ß√£o e tabelas cl√°ssicas. Com os √≠ndices que criei no banco, o Offset funciona super bem aqui.
    

### 7\. Frontend: Busca

**Decis√£o:** Busca no Servidor (Server-side).

*   **Por que?** Carregar todas as operadoras no navegador do cliente pesaria demais a p√°gina inicial. Fazendo a busca no servidor (usando ILIKE no SQL), transferimos o peso do processamento para o banco, que √© feito pra isso, deixando o front leve e r√°pido.
    

### 8\. Frontend: Estado

**Decis√£o:** Composition API & Refs (Simples).

*   **Por que?** N√£o usei Pinia ou Vuex porque n√£o precisava. O estado da aplica√ß√£o √© local (apenas a lista da tela atual ou os detalhes da empresa). Usar uma lib de gerenciamento de estado global s√≥ adicionaria complexidade desnecess√°ria (boilerplate) sem ganho real. Mantive o princ√≠pio KISS (_Keep It Simple, Stupid_).
    

üåü Diferenciais
---------------

Al√©m do b√°sico funcional, implementei alguns pontos extras para garantir qualidade:

*   **Arquitetura Limpa:** O Backend n√£o √© um "arquivo lingui√ßa". Separei rotas, models e conex√£o com banco. O Frontend tamb√©m est√° componentizado.
    
*   **Performance:**
    
    *   No Frontend, uso Promise.all para disparar requisi√ß√µes em paralelo (dados da empresa + despesas), carregando a tela de detalhes na metade do tempo.
        
    *   No Banco, criei √≠ndices espec√≠ficos para as colunas que a gente mais busca (CNPJ e Datas).
        
*   **UX/UI:** O layout √© responsivo, tem feedback visual de "Carregando..." e trata erros de forma amig√°vel, sem estourar c√≥digo na cara do usu√°rio.
    
*   **Resili√™ncia:** O script de ETL tem try/except robusto. Se um arquivo falhar, ele avisa e tenta continuar o resto, em vez de quebrar o processo todo.
    

## üìÇ Estrutura do Projeto

``text
teste-intuitive-care/
‚îú‚îÄ‚îÄ üìÇ backend/            # API RESTful (FastAPI + SQLAlchemy)
‚îú‚îÄ‚îÄ üìÇ frontend/           # Dashboard Interativo (Vue.js 3 + TypeScript)
‚îú‚îÄ‚îÄ üìÇ data/               # Armazenamento de dados (Raw & Processed)
‚îú‚îÄ‚îÄ üìÇ sql/                # Queries Anal√≠ticas (Respostas da Etapa 3.4)  <-- ADICIONADO
‚îú‚îÄ‚îÄ üìÇ src/                # Scripts do Pipeline ETL (Scraping, Valida√ß√£o, Agrega√ß√£o)
‚îú‚îÄ‚îÄ üê≥ docker-compose.yml  # Orquestra√ß√£o do Banco de Dados (PostgreSQL)
‚îî‚îÄ‚îÄ üöÄ run.bat / run.sh    # Scripts de Automa√ß√£o ("One-click setup")
```

## üîé Queries Anal√≠ticas (SQL)

As consultas SQL solicitadas na **Etapa 3.4** foram desenvolvidas e salvas separadamente para facilitar a revis√£o.

* **Localiza√ß√£o:** Pasta `sql/`
* **Como testar:** Voc√™ pode abrir os arquivos .sql em qualquer cliente de banco de dados (pgAdmin, DBeaver, Datagrip) conectado ao banco do projeto.

**Conte√∫do dos Arquivos:**
1.  **Top 5 Crescimento:** Operadoras que mais cresceram entre trimestres.
2.  **Despesas por UF:** Distribui√ß√£o geogr√°fica e m√©dia por estado.
3.  **Despesas Acima da M√©dia:** Operadoras que superaram a m√©dia geral.

üì¨ Postman
----------

Deixei um arquivo collection.json na raiz. √â s√≥ importar no Postman que todas as rotas j√° est√£o configuradas para teste.
