# Teste TÃ©cnico - Intuitive Care

AplicaÃ§Ã£o Full Stack desenvolvida para monitoramento, anÃ¡lise e visualizaÃ§Ã£o de despesas de operadoras de planos de saÃºde, utilizando dados abertos da ANS.

![Dashboard Preview](screenshots/home.png)

## ğŸ“‹ Sobre o Projeto

Este projeto consiste em uma soluÃ§Ã£o ponta-a-ponta (End-to-End) que realiza:
1.  **ETL Automatizado:** Scraping, limpeza, transformaÃ§Ã£o e validaÃ§Ã£o de dados da ANS.
2.  **API RESTful:** Backend performÃ¡tico para servir dados paginados e estatÃ­sticas.
3.  **Dashboard Interativo:** Frontend moderno para visualizaÃ§Ã£o de indicadores e histÃ³rico financeiro.

---

## ğŸš€ Como Executar

O projeto foi desenhado para ser executado de forma simples, mas permite controle granular se necessÃ¡rio.

### PrÃ©-requisitos
- **Docker & Docker Compose** (Essencial para o Banco de Dados)
- **Python 3.10+**
- **Node.js 18+**


# Crie e ative o ambiente virtual
```bash
python -m venv venv
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate
```

### ExecuÃ§Ã£o AutomÃ¡tica âš¡

Criei scripts de automaÃ§Ã£o que configuram o ambiente, sobem o banco, instalam dependÃªncias e rodam o pipeline de dados completo.

**No Windows:**
```bash
./run.bat
```

### ğŸ§ No Linux/Mac
```bash
chmod +x run.sh
./run.sh   
```
**O que esse script faz?**
Ele automatiza o setup para vocÃª nÃ£o perder tempo:

1.  Limpa volumes antigos do Docker (pra garantir que nÃ£o tenha lixo de execuÃ§Ãµes anteriores).
    
2.  Sobe o container do PostgreSQL.
    
3.  Roda o pipeline completo de ETL (scraping -> processamento -> importaÃ§Ã£o pro banco).
    
4.  Te avisa quando terminar.
    

### ğŸ Preparando o Backend

Em um terminal separado:

```bash
# Suba o servidor
uvicorn backend.main:app --reload
```

*   **API:** http://localhost:8000
    
*   **Docs (Swagger):** http://localhost:8000/docs
    

### ğŸ¨ Iniciando o Frontend

Em outro terminal:
```bash
cd frontend
npm install
npm run dev
```

*   **Dashboard:** http://localhost:5173
    

### âš ï¸ Nota sobre os Dados (Backup de SeguranÃ§a)

O script tenta baixar os dados direto do site da ANS em tempo real. Mas a gente sabe que sites do governo Ã s vezes ficam instÃ¡veis ou lentos.

**Plano B:** JÃ¡ deixei os arquivos .csv processados e prontos na pasta data/processed.Se o script de scraping falhar por conexÃ£o, o sistema Ã© inteligente o suficiente para usar esses arquivos locais. Assim vocÃª consegue testar a aplicaÃ§Ã£o sem ficar travado esperando download.

âš–ï¸ Trade-offs e DecisÃµes TÃ©cnicas
---------------------------------

Durante o desenvolvimento, precisei tomar algumas decisÃµes de arquitetura. Abaixo explico o porquÃª de cada escolha, focando no contexto do teste e boas prÃ¡ticas.

### 1\. Processamento de Dados (ETL)

**DecisÃ£o:** Processamento em MemÃ³ria (Pandas).

*   **Por que?** O volume de dados trimestral da ANS, embora pareÃ§a grande em linhas, cabe tranquilamente na memÃ³ria RAM de mÃ¡quinas modernas. Usar Pandas permitiu escrever um cÃ³digo muito mais limpo e rÃ¡pido de implementar do que criar um processamento incremental ou em stream, que seria "overengineering" para esse cenÃ¡rio.
    

### 2\. Tratamento de Dados InvÃ¡lidos

**DecisÃ£o:** Limpeza e PadronizaÃ§Ã£o.

*   **Por que?** Em vez de descartar qualquer linha com erro, optei por tentar salvar o dado. Para CNPJs, removi caracteres nÃ£o numÃ©ricos e garanti o _padding_ com zeros Ã  esquerda. Se mesmo assim o dado for invÃ¡lido, ele Ã© mantido para fins de auditoria, mas nÃ£o entra nas mÃ©tricas financeiras crÃ­ticas.
    

### 3\. Banco de Dados: NormalizaÃ§Ã£o

**DecisÃ£o:** Tabelas Normalizadas (dim\_companies e fact\_expenses).

*   **Por que?** Poderia ter feito uma tabela Ãºnica (plana), mas optei por separar. A dimensÃ£o de empresas (dim\_companies) evita que a gente repita a RazÃ£o Social e UF milhÃµes de vezes na tabela de despesas, economizando espaÃ§o e facilitando a atualizaÃ§Ã£o cadastral se a empresa mudar de nome.
    

### 4\. Banco de Dados: Tipos NumÃ©ricos

**DecisÃ£o:** DECIMAL/NUMERIC ao invÃ©s de FLOAT.

*   **Por que?** Regra de ouro em sistemas financeiros: nunca use Float para dinheiro por causa de erros de arredondamento de ponto flutuante. Usei DECIMAL para garantir precisÃ£o exata nos centavos.
    

### 5\. Backend: Framework

**DecisÃ£o:** FastAPI.

*   **Por que?** Ã‰ mais performÃ¡tico que o Flask (assÃ­ncrono nativo) e a melhor parte: ele jÃ¡ me dÃ¡ a documentaÃ§Ã£o Swagger de graÃ§a e valida os dados de entrada/saÃ­da com o Pydantic. Isso poupou muito tempo de validaÃ§Ã£o manual de JSON.
    

### 6\. EstratÃ©gia de PaginaÃ§Ã£o

**DecisÃ£o:** Offset-based (LIMIT/OFFSET).

*   **Por que?** Num dashboard administrativo, o usuÃ¡rio quer saber "quantas pÃ¡ginas tem" e poder pular da pÃ¡gina 1 para a 10. PaginaÃ§Ã£o por cursor (como em redes sociais) Ã© mais rÃ¡pida para volumes gigantes, mas ruim para navegaÃ§Ã£o e tabelas clÃ¡ssicas. Com os Ã­ndices que criei no banco, o Offset funciona super bem aqui.
    

### 7\. Frontend: Busca

**DecisÃ£o:** Busca no Servidor (Server-side).

*   **Por que?** Carregar todas as operadoras no navegador do cliente pesaria demais a pÃ¡gina inicial. Fazendo a busca no servidor (usando ILIKE no SQL), transferimos o peso do processamento para o banco, que Ã© feito pra isso, deixando o front leve e rÃ¡pido.
    

### 8\. Frontend: Estado

**DecisÃ£o:** Composition API & Refs (Simples).

*   **Por que?** NÃ£o usei Pinia ou Vuex porque nÃ£o precisava. O estado da aplicaÃ§Ã£o Ã© local (apenas a lista da tela atual ou os detalhes da empresa). Usar uma lib de gerenciamento de estado global sÃ³ adicionaria complexidade desnecessÃ¡ria (boilerplate) sem ganho real. Mantive o princÃ­pio KISS (_Keep It Simple, Stupid_).
    

ğŸŒŸ Diferenciais
---------------

AlÃ©m do bÃ¡sico funcional, implementei alguns pontos extras para garantir qualidade:

*   **Arquitetura Limpa:** O Backend nÃ£o Ã© um "arquivo linguiÃ§a". Separei rotas, models e conexÃ£o com banco. O Frontend tambÃ©m estÃ¡ componentizado.
    
*   **Performance:**
    
    *   No Frontend, uso Promise.all para disparar requisiÃ§Ãµes em paralelo (dados da empresa + despesas), carregando a tela de detalhes na metade do tempo.
        
    *   No Banco, criei Ã­ndices especÃ­ficos para as colunas que a gente mais busca (CNPJ e Datas).
        
*   **UX/UI:** O layout Ã© responsivo, tem feedback visual de "Carregando..." e trata erros de forma amigÃ¡vel, sem estourar cÃ³digo na cara do usuÃ¡rio.
    
*   **ResiliÃªncia:** O script de ETL tem try/except robusto. Se um arquivo falhar, ele avisa e tenta continuar o resto, em vez de quebrar o processo todo.
    

## ğŸ“‚ Estrutura do Projeto

```text
teste-intuitive-care/
â”œâ”€â”€ ğŸ“‚ backend/            # API RESTful (FastAPI + SQLAlchemy)
â”œâ”€â”€ ğŸ“‚ frontend/           # Dashboard Interativo (Vue.js 3 + TypeScript)
â”œâ”€â”€ ğŸ“‚ data/               # Armazenamento de dados (Raw & Processed)
â”œâ”€â”€ ğŸ“‚ src/                # Scripts do Pipeline ETL (Scraping, ValidaÃ§Ã£o, AgregaÃ§Ã£o)
â”œâ”€â”€ ğŸ³ docker-compose.yml  # OrquestraÃ§Ã£o do Banco de Dados (PostgreSQL)
â””â”€â”€ ğŸš€ run.bat / run.sh    # Scripts de AutomaÃ§Ã£o ("One-click setup")
```

ğŸ“¬ Postman
----------

Deixei um arquivo collection.json na raiz. Ã‰ sÃ³ importar no Postman que todas as rotas jÃ¡ estÃ£o configuradas para teste.
